# Lecture 7 (Tue 10/24/2023)

Owner: Philip Manfred Pincencia

### Some properties of CDFs:

1. $0\leq F_X(u)\leq 1$
2. If $a<b$, then $F(a)\leq F(b)$, since $P(X\leq b)=P(X\leq a)+P(a<X\leq b) \geq P(X\leq a) + 0$   (i.e**. $F(u)$ is monotone nondecreasing**)
3. $\lim_{u\to\infty} F(u)=1$ and $\lim_{u\to -\infty} F(u)=0$
4. $F(u)$ is right-continuous: from the right is definitely continuous, but not necessarily from the left. 
    
    ![Untitled](Untitled%203.png)
    

### **Some facts:**

- $P(X>u)=P(\{x\leq u\}^c)=1-P(X\leq u)=1-F(u)$
- $P(X<u)=P(X\leq u)-P(X=u)=F(u^-)$
- $P(X\geq u)=1-P(X<u)=1-F(u^-)$
- $P(X =u)=P(X\leq u)-P(X<u)=F(u)-F(u^-)=$ “jump at u”
- $P(a<X\leq b)=P(X\leq b)-P(X\leq a)=F(b)-F(a)$
- $P(a<X<b)=F(b^-)-F(a)$
- $P(a\leq X<b)=F(b^-)-F(a^-)$
- $P(a\leq X\leq b)=F(b)-F(a^-)$

If $F(u)$ is continuous at $u=a$, then there is no jump at $a$. Thus, 

$P(a<X\leq b)=P(a\leq X\leq b)$ since $F(a)=F(a^+)=F(a^-)$. In this case, $P(X=a)=0$

### Example:

In computer languages, there’s a random generator function which is typically type “double”. Can think of it as approximately a random real number in the interval $[0,1]$. What is the CDF of this model random variable? 

Assumption: No preference within $[0,1]$ for any number over any other number. We’ll assume the probability of our random variable $X$ lying in an interval $[a,b]\subseteq [0,1]$ only depends on the gap length $b-a$. We know $P(X\in [0,1])=1$, so $P(X\in[a,b])=b-a$. 

So, $P(X\in[0,u^-])=u-0=u~=~P(X\leq u )=F(u)$  , i.e. CDF. 

It’s true for all $u\in [0,1]$. But we have to expand to $-\infty < u<\infty$. 

So, if $u<0$. then $P(X\leq u)=0$. 

If $u> 1$, then $P(X\leq u)=1$

Note: There are no jumps in $F(u)$. So, $F(u)$ is continuous → $P(X=u)=0$.  

> This is where intuition breaks down, but hey, it’s math.
> 

## Discrete Random Variable

> A discrete random variable $X$ is a random variable which takes on a finite (or countably infinite) set of values. The CDF of any discrete random variable is a “staircase function”: flat + jumps. 

*Computer is not necessarily continuous as the bits are finite.*
> 

## Probability Mass Function (pmf)

→ pmf of a discrete random variable $X$ is $p_X(u)=P(X=u)$

$p_X(u)$ is the jump of the CDF at $u$. We plot pmfs using vertical bars with solid bubbles at the top, labeled with the probability. 

![Untitled](Untitled%204.png)

pmfs are very useful for discrete probabilities. 

Facts: 

- $p_X(u)\geq 0, ~\forall u$
- $\sum_u p_X(u)=1$

Example: Roll a fair die. Define 2 random variables: 

$X$ be -1 if die is even, 1 if odd. $Y$ be -1 if die is $\leq 3$, 1 if die is $\geq 4$. 

Plot the pmfs:

![Untitled](Untitled%205.png)

The pmfs of $X$ and $Y$ are the same, but the random variables $X$ and $Y$ are different. Makes sense because a random variable is just mapping function. As an counterexample, $Y(1)=-1 \neq X(1)=1$ 

### **Look at some special “name” random variables:**

1. **Uniform discrete r.v.:** 
The pmf has a finite number of equally spaced and equal height values. 
    
    ![Untitled](Untitled%206.png)
    
2. **Binomial r.v. (with parameters $n,p$):** 
The pmf: 
For $k=0,1,2,…,n$
    
    $$
    p_X(k)=\binom{n}{k}p^k(1-p^{n-k})
    $$
    
3. **Poisson r.v. (with parameter $\lambda$):**
The pmf: 
For $k=0,1,2,…$
    
    $$
    p_X(k)=\frac{\lambda^ke^{-\lambda}}{k!}
    $$
    
    > Used in applications to model arrival times or amounts.
    > 
    - Proof that $\sum_{k=0}^\infty p_X(k)=1$
        
        $\sum_{k=0}^\infty \frac{\lambda^k e^{-\lambda}}{k!}=e^{-\lambda}\sum_{k=0}^\infty \frac{\lambda^k}{k!}=e^{-\lambda}e^{\lambda}=1$
        
4. **Geometric r.v. (with parameter $p$):**
The pmf: 
For $k=1,2,3,…$

$$
p_X(k)=p(1-p)^{k-1}
$$

> $X$ is the number of flips of a biased coin until 1st head appears.
> 

Fact: $P(X>k)=(1-p)^k$