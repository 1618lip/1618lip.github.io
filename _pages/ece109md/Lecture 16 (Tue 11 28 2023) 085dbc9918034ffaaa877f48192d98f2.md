# Lecture 16 (Tue 11/28/2023)

Owner: Philip Manfred Pincencia

## Two Functions of 2 random variables

$Z=g(X,Y)$, $W=h(X,Y)$. 

Find $f_{Z,W}(u,v)$ in terms of joint pdf $f_{X,Y}(u,v)$

Let say $Z=X+Y$ and $W=X-Y$.

How? Set up joint CDF then differentiate twice. 

$F_{Z,W}(a,b)=P(Z\leq a, W\leq b)=P(Y\leq -X+a, Y\geq X-b)=P((X,Y)\in T)$, where $T=\{(u,v):v\leq -u+a, v\geq u-b\}$

$=\int_{-\infty}^\frac{a+b}{2} \int_{u-b}^{a-u}f_{X,Y}(u,v)~dvdu$

Now, take partial derivative w.r.t. $a$: 

$$
\frac{\partial}{\partial a} \int_{-\infty}^\frac{a+b}{2} \int_{u-b}^{a-u}f_{X,Y}(u,v)~dvdu
$$

Use Leibniz: 2nd term gone. 

$$
\frac{\partial}{\partial a} \int_{\frac{a+b}{2}-b}^{a-\frac{a+b}{2}}f_{X,Y}(\frac{a+b}{2},v)~dv\cdot \frac{\partial}{\partial a} +  \int_{-\infty}^\frac{a+b}{2} \frac{\partial }{\partial a}\int_{u-b}^{a-u}f_{X,Y}(u,v)~dvdu
$$

$$
\int_{-\infty}^\frac{a+b}{2} f_{X,Y}(u,a-u)~du
$$

Now take the partial w.r.t. $b$

$$
\frac{\partial }{\partial b}\int_{-\infty}^\frac{a+b}{2} f_{X,Y}(u,a-u)~du=\frac{1}{2}f_{X,Y}(\frac{a+b}{2},\frac{a-b}{2})
$$

<aside>
ðŸ’¡ $f_{Z,W}(a,b)=\frac{1}{2}f_{X,Y}(\frac{a+b}{2},\frac{a-b}{2})$

</aside>

Special case: $X,Y$ are iid uniform on $[0,1]$.

So, 

$$
f_{Z,W}(a,b)=\frac{1}{2}f_{X}(\frac{a+b}{2})f_Y(\frac{a-b}{2})
$$

So, $f_X(u)=f_Y(v)=1$, if $0\leq u,v\leq 1$

So, $f_{Z,W}(a,b)=\frac{1}{2}$ if $0\leq \frac{a+b}{2},\frac{a-b}{2}\leq 1$, 0 else. 

![Untitled](Untitled%2012.png)

We gotta be inside that diamond shaped. 

---

Before, we see that if $Y=aX+b$, $Var(Y)=a^2\cdot Var(X)$

Suppose $Z=g(X_1, X_2, â€¦,X_n)$. 

For $n=2$, 

$$
E[g(X,Y)]=\int_{-\infty}^\infty \int_{-\infty}^\infty g(u,v)f_{X,Y}(u,v)~dudv\equiv \sum_{-\infty}^\infty \sum_{-\infty}^\infty g(u,v)p_{X,Y}(u,v)~dudv
$$

### Example

Sum of Two random variables

$$
E[X+Y]=\int_{-\infty}^\infty \int_{-\infty}^\infty (u+v)f_{X,Y}(u,v)~dudv\\=\int_{-\infty}^\infty u\int_{-\infty}^\infty f_{X,Y}(u,v)~dvdu+\int_{-\infty}^\infty v\int_{-\infty}^\infty f_{X,Y}(u,v)~dudv=\int_{-\infty}^\infty uf_X(u)~du+\int_{-\infty}^\infty vf_X(v)~dv=E[X]+E[Y]
$$

<aside>
ðŸ’¡ $E[X_1+X_2+â€¦+X_n]=E[X_1]+E[X_2]+â€¦+E[X_n]$
True regardless of independence

</aside>

## Covariance

$Cov(X,Y)=E[(X-E[X])(Y-E[Y])]$

Note: $Cov(X,X)=E[(X-E[X])^2]$

Covariance measure how correlated the two random variables are.

In some cases, here is the easier way: 

Let $E[X]=\mu_X$ and $E[Y]=\mu_Y$

$Cov(X,Y)=E[(X-\mu_X)(Y-\mu_Y)]=E[XY]-\mu_YE[X]-\mu_XE[Y]+\mu_X\mu_Y=E[XY]-E[X]E[Y]$

<aside>
ðŸ’¡ $Cov(X,Y)=E[XY]-E[X]E[Y]$
$Cov(aX,bY)=ab\cdot Cov(X,Y)$
$Cov(X,Y+Z)=Cov(X,Y)+Cov(X,Z)$

</aside>

### Correlation Coefficient

$\rho_{X,Y}=\frac{Cov(X,Y)}{\sigma_X \sigma_Y}$

Note: 

$$
\rho_{X,Y}=E[(\frac{X-E[X]}{\sigma_X})(\frac{Y-E[Y]}{\sigma_Y})]
$$

If $\rho_{X,Y}=0$, then we say $X,Y$ are uncorrelated â†’ $Cov(X,Y)=0\to E[XY]=E[X]E[Y]$

*Fact*: $|\rho_{X,Y}|\leq 1$

> Correlation $\neq$ Independence   (except Gaussian)

Independent â†’ Uncorrelated   (not if and only if)
>